{"metadata":{"name":"","language":"ocaml"},"worksheets":[{"cells":[{"metadata":{},"cell_type":"markdown","source":"(The following line improves the printing of code values.)"},{"metadata":{},"input":"Topdirs.dir_install_printer Format.std_formatter Longident.(Ldot(Lident \"Print_code\", \"print_code\"));;","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n\n## Binding-time analysis\n\nWe have [seen](staging.html) a general procedure for staging functions, which\nbegins with a program parameterised by some \"static\" values and some \"dynamic\"\nvalues.  The first steps in staging a program involve determining which input\nvalues are static (known at code generation time) and which values are dynamic\n(available only later), then using this information to add the staging\nannotations brackets (`.< >.`) and escape (`.~`).\n\nThis process of classifying variables and annotating expressions is sometimes\ncalled *binding-time analysis*, a term borrowed from the partial evaluation\ncommunity.  We can illustrate the process of binding-time analysis in by\nlooking at the staging of the `pow` function:"},{"metadata":{},"input":"let rec pow x n =\n  if n = 0 then 1\n  else x * pow x (n - 1)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nBinding-time analysis proceeds as follows:\n\n* First, determine which inputs of the program are available at\n  code-generation time.  For `pow` we're interested in the cases where the\n  exponent `n` is static (known during code generation) and the base `x` is\n  dynamic.\n\n* Next, analyse each sub-expression.  If every free variable in a\n  sub-expression is static, then the whole sub-expression is static and should\n  be evaluated in the present stage.  If, on the other hand, an expression\n  contains some dynamic variables then the expression should be considered\n  dynamic and its evaluation delayed to the future stage.  Recall that\n  *quoting* delays the evaluation of an expression and *escaping* causes the\n  evaluation of a sub-expression within a quoted expression.\n\n  Let's look at the sub-expressions of `pow`:\n\n  * `n` is static\n  * `x` is dynamic\n  * `n = 0` is static, since `n` is static.\n  * `n - 1` is static, since `n` is static\n  * `if n = 0 then … else …` is static, since the condition is static\n  * `x * pow x (n - 1)` is dynamic, since `x` is dynamic\n  * `pow x (n - 1)` is static, since `pow` is static\n\n  These considerations lead to staging `pow` as follows:"},{"metadata":{},"input":"let rec pow x n =\n  if n = 0 then .< 1 >.\n  else .< .~x * .~(pow x (n - 1)) >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n  Both branches of a conditional expression must have the same type, so we\n  have quoted the first branch (`1`) so that it matches the type of the second\n  branch, i.e. `int code`.\n\nWe also looked at two ways to stage the `dot` function based on different\nbinding-time analyses, first treating the length as static and the vectors as\ndynamic,  and then treating both the length and the first vector as static.\n\nThe goal of binding-time analysis is to make it possible to evaluate as much\nas possible during code generation, making the generated program as small and\nefficient as possible.\n\n## Possibly-static values\n\nIn the functions we have looked at so far we have been able to classify each\nvariable as either static or dynamic.  Sometimes the situation is a little\nmore complicated: we may wish to run the same function on both static and\ndynamic data.  For such cases it can be helpful to have a type of\n*possibly-static data*, which can be defined as follows:"},{"metadata":{},"input":"type 'a sd =\n  | Sta : 'a      -> 'a sd\n  | Dyn : 'a code -> 'a sd","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nA value of type `t sd` is either a static value of type `t` or a dynamic value\nof type `t code`.  We can use `sd` to write functions which can operate on\neither static or dynamic data, evaluating as much as possible using the data\navailable.  For example, here is an addition function written in this style:"},{"metadata":{},"input":"let add_sd : int sd -> int sd -> int sd =\n  fun x y -> match x, y with\n    Sta l, Sta r -> Sta (l + r)\n  | Sta 0, Dyn v\n  | Dyn v, Sta 0 -> Dyn v\n  | Sta l, Dyn v\n  | Dyn v, Sta l -> Dyn .< l + .~v >.\n  | Dyn l, Dyn r -> Dyn .< .~l + .~r >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThe `add_sd` function takes two `int sd` values and inspects them to determine\nwhether they are static or dynamic.  If both values are static then the\naddition can be performed immediately.  If one variable is statically known to\nbe zero then the addition can be elided altogether.  In other cases the\naddition must be delayed until all the data is available.  The generated code\nis constructed using either cross-stage persistence or splicing depending on\nwhether the available data is static (of type `int`) or dynamic (of type `int\ncode`).\n\nThe following function is often useful when programming with possibly-static\nvalues.  The function `unsd` converts a possibly-static value into a\ndefinitely-dynamic value, using cross-stage persistence to turn static values\ninto code:\n "},{"metadata":{},"input":"let unsd : 'a.'a sd -> 'a code =\n function\n    Sta v -> .< v >.\n  | Dyn v -> v","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n## Partially-static data structures\n\nIn other cases the situation is yet more complex.  Situations may arise where\npart of a particular data structure is static and part dynamic.  We will look\nat how to deal with such situations by using the stack machine as an example.\n\n### Stack machines again\n\nIn the [monads lectures](monads.html) we considered a simple stack machine\nwith three instructions:\n\n* `add` expects two integers on the top of the stack; it removes them and adds\n  their sum to the stack.\n\n* `_if_` expects a boolean `c` and two additional values `x` and `y` on the\n  top of the stack.  These are removed and either `x` or `y` is placed on the\n  stack according to whether `c` is `true` or `false`\n\n* `push_const` adds a value to the top of the stack\n\n### Stack machines: higher-order vs first-order\n\nWe looked at two approaches to implementing stack machines.\n\nThe first approach treats a stack machine as a function from an input stack to\nan output stack, which we might define as follows:"},{"metadata":{},"input":"type ('s, 't) t = 's -> 't","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThen each instruction is simply implemented as a particular function on\nstacks.  For example, here is a definition of `add`:"},{"metadata":{},"input":"let add (x, (y, s)) = (x + y, s)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nSince a stack machine is implemented as a function we might call this approach\n*higher-order*.\n\nThe second approach treats a stack machine as a sequence of instructions,\nwhich we might define as follows:"},{"metadata":{},"input":"type (_, _) instr =\n   Add : (int * (int * 's), int * 's) instr\n | If : (bool * ('a * ('a * 's)), 'a * 's) instr\n | PushConst : 'a -> ('s, 'a * 's) instr\n\ntype (_, _) instrs =\n   Stop : ('s, 's) instrs\n | ::   : ('s1, 's2) instr * ('s2, 's3) instrs -> ('s1, 's3) instrs","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":">"},{"metadata":{},"input":"type ('s, 't) t = ('s, 't) instrs","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThen each instruction is simply a singleton list of the corresponding\nconstructor.  For example, here is a definition of `add`:"},{"metadata":{},"input":"let add = Add :: Stop","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nSince a stack machine is implemented as an inspectable piece of data we might\ncall this approach *first-order*.\n\n### Recap: optimising stack machines\n\nWe saw that the higher-order approach leads to stack machines which are more\ndifficult to optimize than the first-order approach.\n\nWith the first-order approach optimizing a stack machine is simply a matter of\ntransforming a data structure.\n\nWith the higher-order approach optimization is difficult because functions are\nopaque values which cannot be inspected.  There is no way of telling whether a\nparticular function represents `add` (for example), and so it is not possible\nin general to optimize a stack machine before it is run by reducing additions\nof constants.\n\n### Stack machines: basic interface\n\nWe will use a slightly simplified interface to stack machines, omitting the\nresult parameter that appeared in the interface in the earlier presentation.\nAs before, a value of type `('s, 't) t` represents a program that transforms\na stack of type `'s` into  a stack of type `'t`."},{"metadata":{},"input":"module type STACKM =\nsig\n  type ('s, 't) t\n  val nothing : ('s, 's) t\n  val (++) : ('r, 's) t ->\n             ('s, 't) t ->\n             ('r, 't) t\n  val add : (int * (int * 's),\n                    int * 's) t\n  val _if_ : (bool * ('a * ('a * 's)),\n                            'a * 's) t\n  val push_const : 'a -> ('s,\n                     'a * 's) t\n  val execute : ('s, 't) t -> 's -> 't\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Higher-order stack machines\n\nHere is an implementation of stack machines using the higher-order\napproach:"},{"metadata":{},"input":"module StackM : STACKM =\nstruct\n  type ('s, 't) t = 's -> 't\n  let nothing s = s\n  let (++) f x s = x (f s)\n  let add (x, (y, s)) = ((x + y, s))\n  let _if_ (c, (x, (y, s))) = ((if c then x else y), s)\n  let push_const v s = (v, s)\n  let execute f s = f s\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Optimising higher-order stack machines\n\nWe can illustrate the overhead involved in evaluating a stack machine by\ntracing the evaluation of a particular program.  The following program pushes\n`3` onto the top of the stack, then pushes `4`, then pops the top two numbers,\nadds them and pushes the result:"},{"metadata":{},"input":"  let open StackM in\n  push_const 3 ++\n  push_const 4 ++\n  add","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nResolving the names `push_const` and `add` to their definitions produces the\nfollowing program:\n\n```\n   (fun s -> (3, s)) ++\n   (fun s -> (4, s)) ++\n   (fun (x, (y, s)) -> ((x + y, s)))\n```\n\nResolving and reducing `++` gives us the following term:"},{"metadata":{},"input":"(fun s ->\n   (fun (x, (y, s)) -> ((x + y, s)))\n   ((fun s -> (fun s -> (4, s)) ((fun s -> (3, s)) s)) s))","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nAt this point the program has been reduced to a value, so no further\nevaluation takes place until it is applied to a an argument.  However, it is\neasy to see that the program could be further improved by evaluating some\nsub-terms in advance.  Reducing the applications of `fun` terms gives the\nfollowing program,"},{"metadata":{},"input":"(fun (x, (y, s)) -> (4 + 3, s))","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nat which point the addition can also be reduced to give the following optimal\nterm:"},{"metadata":{},"input":"(fun (_, (_, s)) -> (7, s))","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nAs this example suggests, the main difficulty in optimising stack machine\nprograms written with the higher-order approach is the fact that no evaluation\ntakes place \"under lambda\" --- i.e. function bodies are never reduced until\nthe function arguments are available.  Staging makes it possible to reduce\nunder lambda, improving the efficiency of programs. \n\n### Staging the higher-order stack machine\n\nLet's look at a staged implementation of the stack machine.  We can extend the\n`STACKM` interface with an additional function `compile` that converts a stack\nmachine program to `code`:"},{"metadata":{},"input":"module type STACKM_staged =\nsig\n  include STACKM\n  val compile : ('s, 't) t -> ('s -> 't) code\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nSince the `compile` function returns a value of type `code`, it will allow us\nto inspect the generated code before we run it.\n\nHere is a implementation of `StackM_staged`, the result of annotating the\nmodule `StackM` when stacks are treated as dynamic data:"},{"metadata":{},"input":"module StackM_staged : STACKM_staged =\nstruct\n  type ('s, 't) t = 's code -> 't code\n  let nothing s = s\n  let (++) f x s = x (f s)\n  let add p =\n    (.< let (x, (y, s)) = .~p in\n       (x + y, s) >.)\n  let _if_ p =\n    .< let (c, (x, (y, s))) = .~p in\n        ((if c then x else y), s) >.\n  let push_const v s =\n    .< (v, .~s) >.\n\n  let compile f = .< fun s -> .~(f .<s>. ) >.\n  let execute f = Runcode.(!.(compile f))\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nA couple of points deserve mention.  The `compile` function corresponds to the\n`back` function in the [idealized staging process](staging.html), and\n`execute` is a simple use of `run`.  The two functions which inspect the\nstack, `add` and `_if_`, introduce `let` bindings so that the pattern matching\nagainst the stack takes place in the future stage, when the stack value is\navailable, not in the present stage, where we have only uninspectable code\nvalues available.\n\nWe can use `compile` to inspect the code generated by the staged stack\nmachine:"},{"metadata":{},"input":"open StackM_staged","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"input":"compile (push_const true ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"input":"compile (push_const 3 ++ push_const 4 ++\n         push_const false ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"input":"compile (push_const 3 ++ push_const 4 ++\n         push_const false ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nAs these examples show, the generated code is not yet optimized.  We still\nhave work to do if we want the staged program to run faster than the original.\n\n### Partially-static stacks\n\nOur initial implementation of staged stack machines does not perform any\noptimization because it treats the entire stack as dynamic.  The optimizations\nthat we hope to make can only be applied when enough of the data is statically\nknown.  For example, we can only reduce an `add` instruction statically if we\nknow enough about the state of the stack to be able to determine the values of\nthe top two elements.  However, we cannot simply treat the entire stack as\nstatic, since the state of the input stack is not generally known in advance.\nWe need a stack representation which allows us to treat some elements as\nstatic and some elements as dynamic.\n\nThe following data type allows us to represent stacks where only some of the\nelements are statically known:"},{"metadata":{},"input":"type 'a stack =\n    Tail : 'a code -> 'a stack\n  | :: : 'a sd * 'b stack -> ('a * 'b) stack","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nA value of type `stack` is either a dynamic tail about which we know nothing\nor a value `v :: s` where `v` is a possibly-static value and `s` is a `stack`.\nHere are some `stack` values:\n\n* The completely-dynamic stack about which nothing is known, including the\n  length:\n `Tail .< s >.`\n\n* A two-value stack which is fully-known statically.\n  `Sta 2 :: Sta 3 :: Tail .< () >.`\n\n  (The tail is still represented as a dynamic value using our definition; if\n  necessary we could extend the definition to support static tails.)\n\n* A two-value stack where neither element is known statically\n  `Dyn .< x >. :: Dyn .<y>. :: Tail .< () >.`\n\n* A two-value stack where the second element is known statically\n  `Dyn .< x >. :: Sta 3 :: Tail .< () >.`\n\nTwo functions on partially-static stacks will prove useful.  The first,\n`unsd`, turns a partially-static stack into a fully-dynamic stack, much as\n`sd` turns a possibly-static value into a definitely dynamic value:"},{"metadata":{},"input":"let rec unsd_stack : type s.s stack -> s code =\n  function\n    Tail s -> s\n  | c :: s -> .< (.~(unsd c), .~(unsd_stack s)) >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThe second, `extend`, exposes some of the structure of a possibly-dynamic\nstack by turning a dynamic tail into a stack with one dynamic element and a\ndynamic tail:"},{"metadata":{},"input":"let extend : 'a 'b.('a * 'b) stack -> ('a * 'b) stack =\n function\n    Tail s -> Dyn .< fst .~s >.  :: Tail .< snd .~s >.\n  | _ :: _ as s -> s","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nHere's `extend` in action:"},{"metadata":{},"input":"extend (Tail .< (1, (2, ())) >.)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nWe're now ready to implement a stack machine program as a function from a\npartially-static stack to a partially-static stack:"},{"metadata":{},"input":"type ('s, 't) t = 's stack -> 't stack","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Stack machine: optimising add\n\nWe'll start with an implementation of `add`.  The behaviour of `add` depends\non how much of the stack is statically-known.  If the top two elements are\nboth static then `add` performs the addition statically.  In other cases,\n`add` generates code to perform the addition, exposing the structure of the\nstack as necessary to ensure that there are at least two elements available:"},{"metadata":{},"input":"let rec add : type s.(int * (int * s), int * s) t = function\n    Sta x :: Sta y :: s -> Sta (x + y) :: s\n  | x :: y :: s -> Dyn .< .~(unsd x) + .~(unsd y) >.  :: s\n  | (Tail _ as s) -> add (extend s)\n  | c :: (Tail _ as s) -> add (c :: extend s)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Stack machine: optimising _if_\n\nSimilarly, `_if_` performs the branch statically if the top element of the\nstack is known statically; otherwise, it exposes as much of the structure of\nthe stack as is necessary and generates code to perform the branch:"},{"metadata":{},"input":"let rec _if_ : type s a.(bool * (a * (a * s)), a * s) t =\n function\n | Sta true :: x :: y :: s -> x :: s\n | Sta false :: x :: y :: s -> y :: s\n | Dyn c :: x :: y :: s ->\n   Dyn .< if .~c then .~(unsd y) else .~(unsd x) >.  :: s\n | (Tail _ as s) -> _if_ (extend s)\n | c :: (Tail _ as s) -> _if_ (c :: extend s)\n | c :: x :: (Tail _ as s) -> _if_ (c :: x :: extend s)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Stack machine: optimising push_const\n\nThe implementation of `push_const` is simple, since there is no need\nto inspect the stack:"},{"metadata":{},"input":"let push_const v s = Sta v :: s","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Stack machine: top-level compilation\n\nAs before, the `compile` function plays the role of the `back` function in the\n[idealized staging process](staging.html), turning a function on code (`'a\ncode -> 'b code`) into a code function (`('a -> 'b) code`).  It additionally\nconverts between static and dynamic stacks: the input stack `s` is converted\nto a dynamic value `Tail .< s >.` of type `stack` and the output stack is\nconverted from a partially-static stack to a definitely-dynamic stack using\n`unsd_stack`:"},{"metadata":{},"input":"let compile f =\n  .< fun s -> .~(unsd_stack (f (Tail .< s >.)) ) >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nHere is the complete implementation of the improved staged stack machine:"},{"metadata":{},"input":"module StackM_staged_improved : STACKM_staged =\nstruct\ntype ('s, 't) t = 's stack -> 't stack\n  let rec add : type s.(int * (int * s), int * s) t = function\n      Sta x :: Sta y :: s -> Sta (x + y) :: s\n    | x :: y :: s -> Dyn .< .~(unsd x) + .~(unsd y) >.  :: s\n    | (Tail _ as s) -> add (extend s)\n    | c :: (Tail _ as s) -> add (c :: extend s)\n  let rec _if_ : type s a.(bool * (a * (a * s)), a * s) t = function\n    | Sta true :: x :: y :: s -> x :: s\n    | Sta false :: x :: y :: s -> y :: s\n    | Dyn c :: x :: y :: s ->\n      Dyn .< if .~c then .~(unsd y) else .~(unsd x) >.  :: s\n    | (Tail _ as s) -> _if_ (extend s)\n    | c :: (Tail _ as s) -> _if_ (c :: extend s)\n    | c :: x :: (Tail _ as s) -> _if_ (c :: x :: extend s)\n  let push_const v s = Sta v :: s\n  let nothing s = s\n  let (++) f x s = x (f s)\n  let compile f =\n  .< fun s -> .~(unsd_stack (f (Tail .< s >.)) ) >.\n  let execute f = Runcode.(!.(compile f))\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":">"},{"metadata":{},"input":"open StackM_staged_improved","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Stack machine: flexible optimisation\n\nInspecting the code generated by `compile` shows how partially-static data\nhelps to generate optimal code.\n\nIf nothing is known about the input stack then the code generated is the same\nas in the initial staged implementation:"},{"metadata":{},"input":"compile add","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"input":"compile _if_","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nIf the top element of the stack before a branch is known statically then the\nbranch is eliminated from the generated code:"},{"metadata":{},"input":"compile (push_const true ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"input":"compile (push_const false ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nIf the top three elements of the stack before a branch are all known\nstatically then the branch can be compiled to a simple push:"},{"metadata":{},"input":"compile (push_const 3 ++ push_const 4 ++\n         push_const false ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nSimilarly, if the top two elements of the stack before an `add` are known\nstatically then the add can be performed during code generation:"},{"metadata":{},"input":"compile (push_const 3 ++ push_const 4 ++\n         add ++ push_const 2 ++\n         push_const false ++ _if_)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### Stack machine summary\n\nWe have seen four approaches to implementing stack machines.\n\n* The monadic, higher-order approach is very expressive and has a simple\n  implementation, but is difficult to optimise.\n\n  ```\n  type ('s, 't) t = 's -> 't\n  let add (x, (y, s)) = (x + y, s)\n  ```\n\n* The applicative, first-order approach makes optimisation easier at the cost\n  of some expressiveness.  However, some *interpretative overhead* remains,\n  since evaluating a program involves branching on the representation of a\n  sequence of instructions.\n\n  ```\n  type ('s, 't) t = ('s, 't) instrs\n  let add = Add :: Stop\n  ```\n\n* The naive staging of the higher-order approach results in a stack machine\n  with few opportunities for optimization:\n\n  ```\n  type ('s, 't) t = 's code -> 't code\n  let add p = .<let (x, (y, s)) = .~p in (x + y, s)>.\n  ```\n\n* Using a partially-static representation of stacks exposes opportunities for\n  optimization, making it possible to generate optimal code:\n\n  ```\n  type ('s, 't) t = 's stack -> 't stack\n  let rec add : type s.(int * (int * s), int * s) t =\n   function\n      Sta x :: Sta y :: s -> Sta (x + y) :: s\n    | …\n  ```\n"}],"metadata":{}}],"nbformat":3,"nbformat_minor":0}