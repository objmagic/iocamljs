{"metadata":{"name":"","language":"ocaml"},"worksheets":[{"cells":[{"metadata":{},"cell_type":"markdown","source":"(The following line improves the printing of code values.)"},{"metadata":{},"input":"Topdirs.dir_install_printer Format.std_formatter Longident.(Ldot(Lident \"Print_code\", \"print_code\"));;","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n## Binding-time analysis\n\nWe have [seen](staging.html) a general procedure for staging functions, which\nbegins with a program parameterised by some \"static\" values and some \"dynamic\"\nvalues.  The first steps in staging a program involve determining which input\nvalues are static (known at code generation time) and which values are dynamic\n(available only later), then using this information to add the staging\nannotations brackets (`.< >.`) and escape (`.~`).\n\nThis process of classifying variables and annotating expressions is sometimes\ncalled *binding-time analysis*, a term borrowed from the partial evaluation\ncommunity.  We can illustrate the process of binding-time analysis in by\nlooking at the staging of the `pow` function:"},{"metadata":{},"input":"let rec pow x n =\n  if n = 0 then 1\n  else x * pow x (n - 1)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nBinding-time analysis proceeds as follows:\n\n* First, determine which inputs of the program are available at\n  code-generation time.  For `pow` we're interested in the cases where the\n  exponent `n` is static (known during code generation) and the base `x` is\n  dynamic.\n\n* Next, analyse each sub-expression.  If every free variable in a\n  sub-expression is static, then the whole sub-expression is static and should\n  be evaluated in the present stage.  If, on the other hand, an expression\n  contains some dynamic variables then the expression should be considered\n  dynamic and its evaluation delayed to the future stage.  Recall that\n  *quoting* delays the evaluation of an expression and *escaping* causes the\n  evaluation of a sub-expression within a quoted expression.\n\n  Let's look at the sub-expressions of `pow`:\n\n  * `n` is static\n  * `x` is dynamic\n  * `n = 0` is static, since `n` is static.\n  * `n - 1` is static, since `n` is static\n  * `if n = 0 then … else …` is static, since the condition is static\n  * `x * pow x (n - 1)` is dynamic, since `x` is dynamic\n  * `pow x (n - 1)` is static, since `pow` is static\n\n  These considerations lead to staging `pow` as follows:"},{"metadata":{},"input":"let rec pow x n =\n  if n = 0 then .< 1 >.\n  else .< .~x * .~(pow x (n - 1)) >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n  Both branches of a conditional expression must have the same type, so we\n  have quoted the first branch (`1`) so that it matches the type of the second\n  branch, i.e. `int code`.\n\nWe also looked at two ways to stage the `dot` function based on different\nbinding-time analyses, first treating the length as static and the vectors as\ndynamic, and then treating both the length and the first vector as static.\n\nThe goal of binding-time analysis is to make it possible to evaluate as much\nas possible during code generation, making the generated program as small and\nefficient as possible.\n\n## Possibly-static data\n\nIn the functions we have looked at so far we have been able to classify each\nvariable as either static or dynamic.  Sometimes the situation is a little\nmore complicated: we may wish to run the same function on both static and\ndynamic data.  For such cases it can be helpful to have a type of\n*possibly-static data*, which can be defined as follows:"},{"metadata":{},"input":"type 'a sd =\n  | Sta : 'a      -> 'a sd\n  | Dyn : 'a code -> 'a sd","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nA value of type `t sd` is either a static value of type `t` or a dynamic value\nof type `t code`.  We can use `sd` to write functions which can operate on\neither static or dynamic data, evaluating as much as possible using the data\navailable.\n\nThe following function is often useful when programming with\npossibly-static values.  The function `cd` converts a possibly-static\nvalue into a definitely-dynamic value, using cross-stage persistence\nto turn static values into code:"},{"metadata":{},"input":"let cd : 'a. 'a sd -> 'a code =\n fun sd -> match sd with\n  | Sta s -> .< s >.  (* (cross-stage persistence) *)\n  | Dyn d -> d","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nHere is an example of possibly-static data.  Given an interface for\ndefining numerical functions"},{"metadata":{},"input":"module type NUM = sig\n  type t\n  val (<+>) : t -> t -> t\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nand corresponding overloaded functions"},{"metadata":{},"input":"let (<+>) {N:NUM} (x:N.t) y = N.(x <+> y)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nwe can define addition on possibly-static integers:"},{"metadata":{},"input":"implicit module Num_int_sd: NUM with type t = int sd =\nstruct\n  type t = int sd\n  let (<+>) l r = match l, r with\n   | Sta 0, v\n   | v, Sta 0 -> v\n   | Sta l, Sta r -> Sta (l + r)\n   | l, r -> Dyn .< .~(cd l) + .~(cd r) >.\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThen adding static numbers gives a static result:"},{"metadata":{},"input":"Sta 2 <+> Sta 3","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nand adding a static zero to another number has no effect, even if that\nnumber is dynamic:"},{"metadata":{},"input":"Sta 0 <+> Dyn .< 3 >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nHowever, adding two dynamic numbers generates code which will perform\nan addition when evaluated:"},{"metadata":{},"input":"Dyn .< 3 >. <+> Dyn .< 4 >.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n### `dot` with possibly-static elements\n\nIf we extend `NUM` to support multiplication then we can give a new\ndefinition of the [`dot` function](staging.html) that operates on\npossibly-static elements:\n\n```\nlet dot: {N:NUM} -> int -> N.t array -> N.t array -> N.t\n = fun {N:NUM} n l r ->\n    let rec loop i =\n      if i = n then N.zero\n      else l.(i) <*> r.(i)\n        <+> loop (i <+> 1)\n    in loop 0\n```\n\n(The extended `NUM` is left as an exercise for the reader.)\n\nIn fact, this definition does not explicitly use staging at all;\ninstead, it abstracts over the instance of `NUM`. \n\nWe can apply this new `dot` function to possibly-static data:\n\n```\n# dot 3 [|Sta 1      ; Sta 0      ; Dyn .< 3 >.|]\n        [|Dyn .< 2 >.; Dyn .< 1 >.; Sta 0      |]\n - : int sd = Dyn .< 2 >.\n```\n\n## Partially-static data\n\nPossibly-static data improves binding times by supporting situations\nwhere data is not always static or always dynamic.\n\nHowever, possibly-static data is not always sufficient to generate\noptimal code.  For example, the following expression generates code\nwith two additions:"},{"metadata":{},"input":"Sta 2 <+> Dyn .<4>. <+> Sta 3","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nSince addition is associative and commutative, the expression ought to\nbe equivalent to the following"},{"metadata":{},"input":"(Sta 2 <+> Sta 3) <+> Dyn .<4>.","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nwhich generates code with a single addition.  In order to generate\nsuch code from the first expression we must refine the definition of\nintegers and the corresponding addition function to take advantage of\nthe associativity and commutativity laws.\n\n### Partially-static integers\n\nHere is a definition of *partially-static* integers, `ps_int`.  An\ninteger is represented as a sum of a static value and a collection of\ndynamic values:"},{"metadata":{},"input":"type ps_int = { sta : int; dyn : int code list }","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nAnd here is an instance of `NUM` for `ps_int`:"},{"metadata":{},"input":"implicit module Num_ps_int: NUM with type t = ps_int =\nstruct\n  type t = ps_int\n  let (<+>) l r =\n     { sta = l.sta + r.sta; dyn = l.dyn @ r.dyn }\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThe definition of `Num_ps_int` implicitly assumes the associativity\nand commutativity of addition, by freely reordering the static and\ndynamic components of its operands.\n\nAs before, we can define a function `cd` to convert a partially-static\nvalue to a fully-dynamic value:"},{"metadata":{},"input":"let cd { sta; dyn } =\n  List.fold_left (fun x y -> .< .~x + .~y >.) .< sta >. dyn","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nIt is also useful to build a partially-static value from a\nfully-static value:"},{"metadata":{},"input":"let sta x = {sta=x; dyn=[]}","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nand to build a partially-static value from a fully-dynamic value:"},{"metadata":{},"input":"let dyn x = {sta=0; dyn=[x]}","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nFinally, here is a demonstration that our definition of\npartially-static integers accomplish what we set out to do:"},{"metadata":{},"input":"cd (sta 2 <+> dyn .< 4 >. <+> sta 3)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n## `let insertion`\n\n(The code in the remainder of this notebook is not interactive, since\nalgebraic effects cannot currently be compiled to JavaScript.)\n\nMetaOCaml's splicing operation supports constructing code values from\nexisting code values.  However, a naive approach to splicing does not\nalways produce optimal results.  Two problems commonly arise.\n\nThe first problem is that splicing code values \"in place\" may generate\ninefficient code.  For example, here is a function that generates a\nloop; it is parameterised by a function that generates the loop body:\n\n```\nlet generate_loop f = \n .< fun e ->\n   for i = 0 to 10 do print .~( f .<e>.  .<i>. ) done >.\n```\nThere are several ways to call `generate_loop`.  Here is a call that ignores the loop variable `i`:\n\n```\ngenerate_loop (fun e _ -> .< .~e ^ \"\\n\" >.)\n```\n\nAnd here is the resulting code, which evaluates the subexpression `e ^ \"\\n\"` each time round the loop:\n\n```\n.< fun e ->\n   for i = 0 to 10 do\n     print (e ^ \"\\n\")   (* repeated work! *)\n  done >.\n```\n\nThe second problem with a naive approach to splicing is that\nrepeatedly splicing the same code value leads to duplication in the\ngenerated code.  Here is a simple example:\n\n```\nlet x = .< 1 + 2 >. in .< .~x * .~x >.\n```\n\nAnd here is the generated code, which evaluates `1 + 2` twice:\n\n```\n.<(1 + 2) * (1 + 2)>. \n```\n\nThese problems share a common solution.  In each case we can use\n\"`let` insertion\" to bind the spliced expression higher up in the\ngenerated code.  The generated loop can then evaluate the string\nconcatenation once, before the iteration:\n\n\n```\n.< fun e ->\n   let x = e ^ \"\\n\" in\n   for i = 0 to 10 do\n     print x\n  done >.\n```\n\nand the generated arithmetic expression can include just one copy of the addition:\n\n```\n.<let x = 1 + 2\n  in x * x >.\n```\n\n### `let` insertion: a simple implementation\n\n`let` insertion can be implemented straightforwardly using algebraic\neffects.  As usual, we must define both an effect and its handler.\nHere is the definition of the effect, along with a convenience\nfunction for performing the effect:\n\n \n```\neffect GenLet : 'a code -> 'a code\nlet genlet v = perform (GenLet v)\n```\n\nAnd here is the corresponding handler function:\n\n\n```\nlet let_locus : (unit -> 'a code) -> 'a code =\n  fun f -> match f () with\n  | x -> x\n  | effect (GenLet e) k ->\n    .< let x = .~e in .~(continue k  .< x >. )>.\n```\n\nThe `let_locus` function marks the place in the code where a `let`\nbinding should be inserted.  Each call to `genlet` then inserts a\n`let` binding (`.<let x = .~e in ...>.`) at the point where\n`let_locus` was called, and returns the bound variable `.<x>.` to the\ncalling context.  For example, the following code\n\n```\nlet_locus (fun () ->\n  .< w + .~(genlet .< y + z >.) >.)\n```\n\ncaptures the continuation between the call to `let_locus` and the call\nto `genlet`:\n\n\n```\n.< w + .~( - ) >.\n```\n\nthen inserts a `let` binding around the continuation and passes the\ngenerated variable into the hole:\n\n\n```\n.<let x = .~(.<y + z>.) in .~(.< w + .~(.<x>.) >.)>.\n```\n\nHere is the final result:\n\n```\n.< let x = y + z in\n       w + x >.\n```\n\n### Where to insert `let`?\n\nSometimes there are several possible insertion points for a `let` binding.\n\nFor example, consider the following program:\n\n```\n.< fun y -> y + .~(genlet e) >.\n```\n\nWe might like to insert a `let` binding *beneath* the binding for `y`\n\n```\n.< fun y -> let x = .~e in y + x >.\n```\n\nAlternatively, we might like to insert the `let` binding *above* the binding for `y`:\n\n```\n.< let x = .~e in fun y -> y + x >.\n```\n\nIn practice the choice is often constrained: if the expression `e` mentions `y` then inserting the `let` binding beneath the binding for `y` is the only available option.  A reasonable default behaviour is to insert each `let` binding at the highest point in the generated code where the bound expression `e` is well-scoped, and the next section describes an implementation of that behaviour.\n\n### Inserting `let` bindings as high as possible.\n\nHere is a function that checks whether an expression is well-scoped in the calling context: \n\n```\nlet is_well_scoped e =\n  try ignore .< (.~e; ()) >.; true\n  with _ -> false\n```\n\nThe function is based on a built-in behaviour: whenever a code value is spliced, MetaOCaml checks whether the free variables in the expression are in scope --- that is, that the splicing takes place in a dynamic context where those variables are bound.\n\nNext, here is a slightly extended implementation of `genlet`, that catches the `Unhandled` exception and inserts the expression in place.  The `Unhandled` exception is raised whenever an effect is performed outside the scope of a handler for that effect.\n\n```\nlet genlet v =\n  try perform (GenLet v)\n  with Unhandled -> v\n```\n\nFinally, here is an implementation of `let_locus` that uses `is_well_scoped` to search for the highest valid insertion point.\n\n```\nlet let_locus body =\n  try body ()\n  with effect (GenLet e) k when is_well_scoped e ->\n    match perform (GenLet e) with\n    | v -> continue k v\n    | exception Unhandled ->\n      .< let x = .~e in .~(continue k .< x >.)>.\n```\n\n\n### `let rec` insertion\n\nWe now have a technique for inserting `let` bindings.  How might we\nextend the technique to handle (mutual) recursion?\n\nGenerating an arbitrary number of mutually-recursive functions is difficult\nbecause MetaOCaml currently only supports quotations and splicing for\nexpressions, and a group of bindings is not an expression.  We would like to\nwrite\n\n```\nlet rec .~(bindings) in e\n```\n\nbut this would require `.~(bindings)` to expand to a syntax node of the form\n\n```\nx1 = e1 and x1 = e1 and ... and xn = en\n```\n\nwhich is not an expression in the OCaml grammar.  To work around the\ndifficulty we will use an encoding of recursion based on mutable references.\n\nWe can illustrate the reference-based approach with a pair of\nmutually-recursive functions that define (rather inefficient) predicates for\ntesting whether a number is even or odd:"},{"metadata":{},"input":"let rec evenp x =\n  x = 0 || oddp (pred x)\nand oddp x =\n  not (evenp x)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThe idea is to define `evenp` and `oddp` as reference cells which initially\ncontain \"dummy\" functions and then to fill in these cells with the actual\nfunctions at a later point.  All recursive calls then pass through the\nreferences:"},{"metadata":{},"input":"let evenp = ref (fun _ -> assert false) in\nlet oddp  = ref (fun _ -> assert false) in\n\nevenp := (fun x -> x = 0 || (!oddp) (pred x));\noddp := (fun x -> not (!evenp x));","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nIn this way we can write recursive functions without using any explicit\nrecursion.  We have reduced the problem of generating mutually-recursive\nfunctions to the simpler problem of generating the appropriate number of\nnon-recursive `let` bindings and assignments.\n\n### `let rec` insertion with references\n\nWe can use `genlet` together with the technique for encoding recursion using\nreferences to build a library for `let rec` insertion.  Here is the definition\nof a `letrec` function, which is analogous to `genlet`\n\n```\nlet letrec : 'a 'b. (('a -> 'b) code -> ('a -> 'b) code) -> ('a -> 'b) code =\n  fun k ->\n  let r = genlet (.< ref (fun _ -> assert false) >.) in\n  let _ = genlet (.<.~r := .~(k .< ! .~r >.) >.) in\n  .< ! .~r >.\n```\n\nThe `letrec` function has a type typical of fixpoint combinators.  It\naccepts a single argument, namely a function that receives and returns\ncode for a function value, and it builds a recursive binding for that\nvalue.\n\nWe can use `letrec` to build mutually-recursive bindings for `oddp` and\n`evenp`:\n\n```\nlet evenp =\n  let_locus (fun () ->\n  letrec (fun evenp ->\n     let oddp = \n       letrec (fun oddp -> .< (fun x -> not (.~evenp x)) >.)\n     in\n    .< (fun x -> x = 0 || .~(oddp) (pred x)) >.))\n```\n\nThere are two calls to `letrec` in this program.  The first call generates the\nbinding for `evenp` and passes to its argument a variable `evenp` to be used\nfor recursive calls.  Similarly, the second call generates the binding for\n`oddp`, passing to its argument a variable `oddp` and a callback `def_oddp`.\n\nHere is the generated code for `evenp`:\n\n```\n.<\nlet e = ref (fun _  -> assert false) in\nlet o = ref (fun _  -> assert false) in\nlet _ = o := (fun x_9  -> not ((! e) x_9)) in\nlet _ = e := (fun x_11  -> (x_11 = 0) || ((! o) (pred x_11))) in\n! e\n>.\n```\n\n## Staging generic programming\n\nWe now have the ingredients we need to give a staged implementation of\n[generic programming](generic_programming.html).\n\n### Generic programming: binding-time analysis\n\nBinding-time analysis for generic functions is particularly simple.\nRecall that generic functions involve an implicit parameter which\ndescribes the shape of data; for example, in the following signature\nfor `gshow` the implicit argument `{D:DATA}` describes the type `D.t`\nof the second argument:\n\n```\nval gshow: {D:DATA} -> D.t -> string\n```\n\nSince the type at which generic functions are called is (generally)\nknown during compilation and the value is known only when the program\nruns, we will treat type representations (implicit arguments of type\n`DATA`) as static and other arguments as dynamic.\n\nIn our previous implementation of generic programming we used type\nrepresentations to traverse values.  Since staging involves turning\nfunctions into code generators our staged implementation of generic\nprogramming will use type representations to generate code that\ntraverses values.  Furthermore, the code generated will not contain\nthe type equality tests or interpretative overhead that make unstaged\nimplementations of generic programming inefficient.\n\n### Generic programming, staged\n\nThe three ingredients (type equality, shallow traversals, recursive\nschemes) of generic programming need three distinct approaches.\n\n#### Type equality\n\nThe definition of type equality is entirely unchanged:"},{"metadata":{},"input":"type _ type_rep = ..\ntype (_,_) eql = Refl : ('a,'a) eql\nmodule type TYPEABLE = sig\n  type t\n  val type_rep : t type_rep Lazy.t\n  val eqrep : 'other type_rep -> (t, 'other) eql option\nend","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nOnly the *use* of equality changes: we now use it during code\ngeneration rather than during value traversal.\n\n```\nval eqty : {A:TYPEABLE} -> {B:TYPEABLE} -> (A.t, B.t) eq option\n```\n\n#### Shallow traversals\n\nThe shallow traversal functions `gmapT` and `gmapQ` are\ntransformed according to the straightforward binding-time analysis\ndescribed above.  Here is the modified type of `gmapQ`, with a static\ntype representation argument and a dynamic value argument:\n\n```\ntype 'u genericQ = {D:DATA} -> D.t code -> 'u code\nval gmapQ : 'u genericQ -> 'u list genericQ\n```\n\nAnd here is an implementation of `gmapQ` for lists:\n\n```\nimplicit module rec DATA_list {A:DATA}\n    : DATA with type t = A.t list =\n  struct\n    let gmapQ q l =\n    .< match .~l with\n      | [] -> []\n      | h :: t -> [.~(q .< h >.); .~(q .< t >.)] >.\n  end\n```\n\n#### Recursion schemes\n\nGenerating mutually-recursive definitions for `gshow` involves two\nchallenges.\n\nFirst, `gshow` must be able to generate an arbitrary number of\nmutually-recursive functions, since the number of functions generated\ndepends on the number of mutually-recursive types represented by the\n`DATA` argument.  The notes on `let rec` insertion above describe one\napproach to generating mutually-recursive functions.\n\nSecond, the type representations may be *cyclic*: for example, the\ntype representation for `list` contains `list` as a sub-value.  These\ncycles require us to keep track of the types that we have already\nencountered while traversing a type representation.\n\n#### Background: memoization\n\nIn order to handle cyclic type representations we will make use of an common\nfunctional programming technique known as memoization.  The idea of\nmemoization is to avoid repeated computation by creating a table that maps the\narguments of a function to the result of applying the function to those\narguments.  The first time the function is called with a particular argument\nan entry is added to the table; subsequent calls with the same argument\nretrieve the value from the table rather than applying the function again.\n\nWe can see the effects of memoization by transforming the following definition\nof the Fibonacci function:"},{"metadata":{},"input":"let rec fib = function\n    0 -> 0\n  | 1 -> 1\n  | n -> fib (n - 1) + fib (n - 2)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nWith arguments above `30`, `fib` becomes rather sluggish:"},{"metadata":{},"input":"fib 35","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nHere is a memoized version of `fib`:"},{"metadata":{},"input":"let rec fib n =\n try List.assoc n !table\n with Not_found ->\n  let r = fib_aux n in\n  table := (n, r) :: !table;\n  r\nand fib_aux = function\n    0 -> 0\n  | 1 -> 1\n  | n -> fib (n - 1) + fib (n - 2)\nand table = ref []","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nA call to the memoized `fib` function with argument `n` starts by consulting\n`table` to see whether `fib(n)` has already been computed.  If it has, the\nvalue from the table is returned directly.  If it has not then `fib_aux` is\ncalled to compute the value, which is inserted into the table and returned.\nThe recursive calls in `fib_aux` call `fib` rather than `fib_aux` so that the\ncomputations of `fib(n-1)` and `fib(n-2)` are also memoized.\n\nInstead of incorporating the memoization code directly into `fib` we can write\na more general memoization function which can be applied both to `fib` and to\nany other function which we wish to memoize:"},{"metadata":{},"input":"let memoize f n =\n  let table = ref [] in\n  let rec f' n =\n    try List.assoc n !table\n    with Not_found ->\n      let r = f f' n in\n      table := (n, r) :: !table;\n      r\n  in f' n","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n(As the type of `memoize` suggests, it behaves as a kind of fixpoint combinator.)\n\nNow memoizing `fib` involves writing it in an open-recursive style, so that it\naccepts the memoized function as argument:"},{"metadata":{},"input":"let open_fib fib = function\n  0 -> 0\n| 1 -> 1\n| n -> fib (n - 1) + fib (n - 2)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nFinally, we can \"tie the knot\" by applying `memoize` to `open_fib` to produce\na memoized Fibonacci function:"},{"metadata":{},"input":"let fib = memoize open_fib","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThe memoized `fib` function is significantly faster than the original\ndefinition:"},{"metadata":{},"input":"fib 35","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n#### Memoizing generic functions\n\nFor a monomorphic function such as `fib`, an association list (i.e. a\nlist of key-value pairs) serves as a suitable memoization table.\n\nMemoizing a generic function is a little trickier, since each call to\nthe function may involve a different type.  For example, applying\n`gshow` to a list of integers involves recursive calls at the types\n`int` and `int list`.\n\nThe following table, used for memoizing code generators, associates\n`TYPEABLE` keys with `code` values.  Each entry in the table\ncorresponds represents a different type in the generated code."},{"metadata":{},"input":"type _ table =\n   Nil : 'a table\n | Cons : (module TYPEABLE with type t = 'b) *\n          ('b -> 'a) code * 'a table -> 'a table","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThere are three functions.  The `new_map` function creates a fresh\nmemoization table:"},{"metadata":{},"input":"let new_map () = ref Nil","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nThe `add` function adds a new entry:"},{"metadata":{},"input":"let add {T:TYPEABLE} (c : (T.t -> 'a) code) (t : 'a table ref) =\n     t := Cons ((module T), c, !t)","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\nand the `lookup` table searches the table by `TYPEABLE` instance for a suitably-typed code value>"},{"metadata":{},"input":"let rec lookup : {T:TYPEABLE} -> 'a table -> (T.t -> 'a) code option =\n   fun {T:TYPEABLE} tbl ->\n      match tbl with\n       | Nil -> None\n       | Cons ((module T'), v, tbl') ->\n          match T.eqrep (Lazy.force T'.type_rep) with\n           | Some Refl -> Some v\n           | None -> lookup {T} tbl'","cell_type":"code","outputs":[],"language":"python","collapsed":false},{"metadata":{},"cell_type":"markdown","source":"\n#### Generic fixpoints\n\nThe memoization table, together with `let rec` insertion, provide the\ningredients needed to stage generic recursion schemes.  We will define\nrecursive schemes in terms of a \"fixpoint\" function `gfixQ`.  Here is\nan example of `gfixQ` in action, in the definition of a staged\n`gshow`:\n\n```\nlet gshow = gfixQ (fun self {D:DATA} v ->\n .< \"(\"^ .~(constructor_ v)\n        ^ concat \" \" .~(gmapQ_ self v) ^\")\" >.)\n```\n\nAnd here is a definition of `gfixQ`:\n\n```\nlet gfixQ (f : 'v genericQ -> 'v genericQ) =\n  let tbl = new_map () in\n  let rec result {D: DATA} x =\n     match lookup !tbl with\n     | Some g -> .< .~g .~x >.\n     | None -> let g = letrec\n                        (fun self ->\n                          add tbl self;\n                         .< fun y -> .~(f result .<y>.) >.)\n                in .< .~g .~x >.\n   in result\n```\n### Generated code for `gshow`\n\nInstantiating `gshow` at the type `int list -> string` generates the\nfollowing code:\n\n```\nlet show_list = ref (fun _ -> assert false) in\nlet show_int = ref (fun _ -> assert false) in\nlet _ = show_int :=\n fun i ->\n  \"(\"^ string_of_int i ^ String.concat \" \" [] ^\")\" in\nlet _ = show_list :=\n  (fun t ->\n  \"(\"^((match t with [] -> \"[]\" \n                     | _ :: __ -> \"::\") ^\n       ((concat \" \"\n          (match t with\n           | [] -> []\n           | h :: t -> [!show_int h;\n                        !show_list t])) ^\")\"))) in\n!show_list\n```\n\nWhile the code is not especially elegant, it performs around an order\nof magnitude better than the unstaged version.  More careful staging,\nusing both techniques described above (e.g. partially-static data) and\nadditional techniques (`match` insertion and elimination, improved\n`let rec` generation) can deliver further improvements."}],"metadata":{}}],"nbformat":3,"nbformat_minor":0}